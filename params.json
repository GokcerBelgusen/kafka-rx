{"name":"Kafka Rx","tagline":"reactive kafka","body":"# kafka-rx [![Build Status](https://travis-ci.org/cjdev/kafka-rx.svg)](https://travis-ci.org/cjdev/kafka-rx) [![Maven Central](https://img.shields.io/maven-central/v/com.cj/kafka-rx_2.11.svg)](http://search.maven.org/#search%7Cgav%7C1%7Cg%3A%22com.cj%22%20AND%20a%3A%22kafka-rx_2.11%22)\r\n\r\nGeneral Purpose [Kafka](https://kafka.apache.org) Client that Just Behaves\r\n\r\n#### Features\r\n\r\n- thin, reactive adapter around kafka's high level producer and consumer\r\n- per message, fine grained commits semantics\r\n- offset management to keep track of consumer positions\r\n\r\n#### Consuming messages:\r\n\r\nkafka-rx provides a push alternative to kafka's pull-based stream\r\n\r\nTo connect to your zookeeper cluster and process a stream:\r\n\r\n```scala\r\nval connector = new RxConnector(\"zookeeper:2181\", \"consumer-group\")\r\n\r\nconnector.getMessageStream(\"cool-topic-(x|y|z)\")\r\n  .map(deserialize)\r\n  .take(42 seconds)\r\n  .foreach(println)\r\n\r\nconnector.shutdown()\r\n```\r\n\r\nAll of the standard [rx transforms](http://rxmarbles.com/) are available on the resulting stream.\r\n\r\n#### Producing messages\r\n\r\nkafka-rx can also be used to produce kafka streams\r\n\r\n```scala\r\ntweetStream.map(parse)\r\n  .groupBy(hashtag)\r\n  .foreach { (tag, subStream) =>\r\n    subStream.map(toProducerRecord)\r\n      .saveToKafka(kafkaProducer, s\"tweets.$tag\")\r\n      .foreach { savedMessage =>\r\n        savedMessage.commit() // checkpoint position in the source stream\r\n      }\r\n  }\r\n```\r\n\r\nCheck out the [words-to-WORDS](examples/TopicTransformProducer.scala) producer or the [twitter-stream](examples/twitter-stream) demo for a full working example.\r\n\r\n#### Reliable Message Processing\r\n\r\nkafka-rx was built with reliable message processing in mind\r\n\r\nTo support this, every kafka-rx message has a `.commit()` method which optionally takes a user provided merge function, giving the program an opportunity to reconcile offsets with zookeeper and manage delivery guarantees.\r\n\r\n```scala\r\nstream.buffer(23).foreach { bucket =>\r\n  process(bucket)\r\n  bucket.last.commit()\r\n}\r\n```\r\n\r\nIf you can afford possible gaps in message processing you can also use kafka's automatic offset commit behavior, but you are encouraged to manage commits yourself.\r\n\r\nIn general you should aim for idempotent processing, where it is no different to process a message once or many times. In addition, remember that messages are delivered across different topic partitions in a non-deterministic order. If this is important you are encouraged to process each topic partition as an individual stream to ensure there is no interleaving.\r\n\r\n```scala\r\nval numStreams = numPartitions\r\nval streams = conn.getMessageStreams(topic, numStreams)\r\n```\r\n\r\n#### Configuration\r\n\r\nWherever possible, kafka-rx delegates to kafka's internal configuration.\r\n\r\nUse kafka's `ConsumerConfig` for configuring the consumer, and `ProducerConfig` for configuring your producer.\r\n\r\n#### Including in your project\r\n\r\nCurrently kafka-rx is built against kafka 0.8.2.1 and scala 2.11, but should work fine with other similar versions.\r\n\r\nFrom maven:\r\n\r\n```xml\r\n<dependency>\r\n  <groupId>com.cj</groupId>\r\n  <artifactId>kafka-rx_2.11</artifactId>\r\n  <version>0.2.0</version>\r\n</dependency>\r\n```\r\n\r\nFrom sbt:\r\n\r\n```scala\r\nlibraryDependencies += \"com.cj\" % \"kafka-rx\" % \"0.2.0\"\r\n```\r\n\r\n#### Videos & Examples\r\n\r\nFor more code and help getting started, see the [examples](examples/).\r\n\r\nOr, if videos are more your style:\r\n\r\n[![stream processing with kafka-rx](http://img.youtube.com/vi/S-Ynyel9pkk/0.jpg)](http://www.youtube.com/watch?v=S-Ynyel9pkk)\r\n\r\n#### Contributing\r\n\r\nHave a question, improvement, or something you want to discuss?\r\n\r\nIssues and pull requests welcome!\r\n\r\n#### License\r\n\r\nEclipse Public License v.1 - Commission Junction 2015\r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}